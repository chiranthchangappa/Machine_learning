{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search for algorithm tuning\n",
    "import numpy\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2761084412929242\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "names=['preg','plas','pres','skin','test','mass','pedi','age','class']\n",
    "dataframe= read_csv('pima1.csv',names=names)\n",
    "array=dataframe.values\n",
    "x=array[:,0:8]\n",
    "y=array[:,8]\n",
    "alphas = numpy.array([1, 0.1, 0.01, 0.001, 0.0001, 0])\n",
    "param_grid = dict(alpha=alphas)\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid.fit(x, y)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized for algorithm tuning\n",
    "import numpy\n",
    "from pandas import read_csv\n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27610755734028525\n",
      "0.9779895119966027\n"
     ]
    }
   ],
   "source": [
    "names=['preg','plas','pres','skin','test','mass','pedi','age','class']\n",
    "dataframe= read_csv('pima1.csv',names=names)\n",
    "array=dataframe.values\n",
    "x=array[:,0:8]\n",
    "y=array[:,8]\n",
    "param_grid = {'alpha': uniform()}\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100, random_state=7)\n",
    "rsearch.fit(x,y)\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using joblib\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals.joblib import dump\n",
    "from sklearn.externals.joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7874015748031497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chiranth SB\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "names=['preg','plas','pres','skin','test','mass','pedi','age','class']\n",
    "dataframe= read_csv('pima1.csv',names=names)\n",
    "array=dataframe.values\n",
    "x=array[:,0:8]\n",
    "y=array[:,8]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=7)\n",
    "\n",
    "#fit the model on 33%\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#fit the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "dump(model, filename)\n",
    "\n",
    "#some time later....\n",
    "\n",
    "#load the model from disk\n",
    "loaded_model = load(filename)\n",
    "result = loaded_model.score(x_test, y_test)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston.to_csv('boston_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
